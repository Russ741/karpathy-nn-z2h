{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf99c375",
   "metadata": {
    "deletable": false,
    "editable": false,
    "lines_to_next_cell": 2
   },
   "source": [
    "\n",
    "# Worksheet 3 - Multi-Layer Perceptron\n",
    "\n",
    "This is the fourth in a series of companion worksheets for for Andrej Karpathy's [Neural Networks: Zero To Hero](https://karpathy.ai/zero-to-hero.html) videos.\n",
    "\n",
    "It corresponds to the third video in the series, named \"[Building makemore Part 2: MLP](https://www.youtube.com/watch?v=TCH_1BHY58I)\".\n",
    "\n",
    "The rest of the worksheets are listed in the README [here](https://github.com/Russ741/karpathy-nn-z2h/).\n",
    "\n",
    "The overall objective of this worksheet is to write code that generates a word that is similar to a set of example words it is trained on.\n",
    "It does so using a multi-layer neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73bf9a07",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Preamble: Load data\n",
    "\n",
    "Write a function that:\n",
    "* Loads the remotely-hosted [names.txt](https://github.com/karpathy/makemore/blob/master/names.txt) file\n",
    "([raw link](https://github.com/karpathy/makemore/raw/master/names.txt))\n",
    "\n",
    "And returns:\n",
    "* a list of strings (```words```)\n",
    "  * Each string should be equal to the word from the corresponding line of names.txt\n",
    "  * The strings should not include line-break characters\n",
    "\n",
    "Notes:\n",
    "* You can reuse your work from the previous worksheet for this if you like.\n",
    "* The test_words block below will save the loaded words as loaded_words for you to reuse later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfb27ce",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# The sample solution uses this library; if your code doesn't, feel free to remove it.\n",
    "import requests\n",
    "\n",
    "def load_words():\n",
    "# TODO: Implement solution here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e455302b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def test_words():\n",
    "    if not isinstance(loaded_words, list):\n",
    "        print(f\"Expected words to be a list\")\n",
    "        return\n",
    "    if (len_words := len(loaded_words)) != (expected_words := 32033):\n",
    "        print(f\"Expected {expected_words} elements in words, found {len_words} elements\")\n",
    "        return\n",
    "    sorted_words = sorted(loaded_words)\n",
    "    if (zeroth_word := sorted_words[0]) != (expected_zeroth := \"aaban\"):\n",
    "        print(f\"Expected zeroth word in words to be '{expected_zeroth}', was '{zeroth_word}'\")\n",
    "        return\n",
    "    if (final_word := sorted_words[-1]) != (expected_final := \"zzyzx\"):\n",
    "        print(f\"Expected final word in words to be '{expected_final}', was '{final_word}'\")\n",
    "        return\n",
    "    print(\"load_words looks good. Onwards!\")\n",
    "loaded_words = load_words()\n",
    "test_words()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ed4466",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Step 1: Map characters to indices\n",
    "\n",
    "Write a function that takes the following arguments:\n",
    "* ```words``` (list of strings)\n",
    "\n",
    "And returns:\n",
    "* a dict (```stoi```) where\n",
    "  * the key is a character from ```words``` (including '.' for start/end),\n",
    "  * the value is a unique integer, and\n",
    "  * all the values are in the range from 0 to ```len(stoi) - 1``` (no gaps)\n",
    "\n",
    "We'll use these unique integers as an index to represent the characters in a Tensor in later steps\n",
    "\n",
    "Note that for this list of words, the same value of ```stoi``` could be generated without looking at the words at all,\n",
    "but simply by using all the lowercase letters and a period. This approach would be more efficient for this exercise,\n",
    "but will not generalize well conceptually to more complex models in future exercises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ef782d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_stoi(words):\n",
    "# TODO: Implement solution here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e24291",
   "metadata": {
    "deletable": false,
    "editable": false,
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def test_get_stoi():\n",
    "    bigrams = [\n",
    "        ('.', 'h'),\n",
    "        ('h', 'i'),\n",
    "        ('i', '.'),\n",
    "        ('.', 'b'),\n",
    "        ('b', 'y'),\n",
    "        ('y', 'e'),\n",
    "        ('e', '.'),\n",
    "    ]\n",
    "    expected_s = sorted(['.', 'h', 'i', 'b', 'y', 'e'])\n",
    "    stoi = get_stoi(bigrams)\n",
    "    if not isinstance(stoi, dict):\n",
    "        print(f\"Expected stoi to be a dict\")\n",
    "        return\n",
    "    s = sorted(stoi.keys())\n",
    "    if s != expected_s:\n",
    "        print(f\"Expected stoi keys to be {expected_s} when sorted, were {s}\")\n",
    "        return\n",
    "    expected_i = list(range(len(s)))\n",
    "    i = sorted(stoi.values())\n",
    "    if i != expected_i:\n",
    "        print(f\"Expected stoi values to be {expected_i} when sorted, were {i}\")\n",
    "        return\n",
    "    print(\"get_stoi looks good. Onwards!\")\n",
    "test_get_stoi()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6603e1b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Step 2: Map indices to characters\n",
    "\n",
    "Objective: Write a function that takes the following arguments:\n",
    "* a dict (```stoi```) as defined in step 2\n",
    "\n",
    "And returns:\n",
    "* a dict (```itos```) where ```itos``` contains the same key-value pairs as ```stoi``` but with keys and values swapped.\n",
    "\n",
    "E.g. if ```stoi == {'.' : 0, 'b' : 1, 'z', 2}```, then ```itos == {0 : '.', 1 : 'b', 2 : 'z'}```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f179c5e6",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_itos(stoi):\n",
    "# TODO: Implement solution here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c0410c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def test_get_itos():\n",
    "    stoi = {elem:idx for idx, elem in enumerate(string.ascii_lowercase + \".\")}\n",
    "    itos = get_itos(stoi)\n",
    "    if not isinstance(itos, dict):\n",
    "        print(f\"Expected stoi to be a dict\")\n",
    "        return\n",
    "    for c in string.ascii_lowercase + \".\":\n",
    "        c_i = stoi[c]\n",
    "        if (expected_c := itos[c_i]) != c:\n",
    "            print(f\"Expected itos[{c_i}] to be {expected_c}, was {c}\")\n",
    "    print(\"get_itos looks good. Onwards!\")\n",
    "test_get_itos()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c984609",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Step : Generate X and Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05b0c03",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Step : Initialize vector embedding lookup table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d90e4c9",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Step : Convert X to tensor vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d6ba11",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Step : Initialize hidden layer coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051842fc",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Step : Forward propagate through hidden layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2b5db0",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Step : Initialize output layer coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9c686f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Step : Forward propagate through output layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a7b566",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Step : Calculate loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4bd3b0",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Step : Gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf605b7",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Step : Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1589a2",
   "metadata": {
    "deletable": false,
    "editable": false,
    "lines_to_next_cell": 3
   },
   "source": [
    "### Step : Generate words"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
