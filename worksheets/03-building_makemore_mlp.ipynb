{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf99c375",
   "metadata": {
    "deletable": false,
    "editable": false,
    "lines_to_next_cell": 2
   },
   "source": [
    "\n",
    "# Worksheet 3 - Multi-Layer Perceptron\n",
    "\n",
    "This is the fourth in a series of companion worksheets for for Andrej Karpathy's [Neural Networks: Zero To Hero](https://karpathy.ai/zero-to-hero.html) videos.\n",
    "\n",
    "It corresponds to the third video in the series, named \"[Building makemore Part 2: MLP](https://www.youtube.com/watch?v=TCH_1BHY58I)\".\n",
    "\n",
    "The rest of the worksheets are listed in the README [here](https://github.com/Russ741/karpathy-nn-z2h/).\n",
    "\n",
    "The overall objective of this worksheet is to write code that generates a word that is similar to a set of example words it is trained on.\n",
    "It does so using a multi-layer neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73bf9a07",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Preamble: Load data\n",
    "\n",
    "Write a function that:\n",
    "* Loads the remotely-hosted [names.txt](https://github.com/karpathy/makemore/blob/master/names.txt) file\n",
    "([raw link](https://github.com/karpathy/makemore/raw/master/names.txt))\n",
    "\n",
    "And returns:\n",
    "* a list of strings (```words```)\n",
    "  * Each string should be equal to the word from the corresponding line of names.txt\n",
    "  * The strings should not include line-break characters\n",
    "\n",
    "Notes:\n",
    "* You can reuse your work from the previous worksheet for this if you like.\n",
    "* The test_words block below will save the loaded words as loaded_words for you to reuse later\n",
    "\n",
    "Video: [0:09:10](https://youtu.be/TCH_1BHY58I?t=550)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfb27ce",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# The sample solution uses this library; if your code doesn't, feel free to remove it.\n",
    "import requests\n",
    "\n",
    "def load_words():\n",
    "# TODO: Implement solution here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e455302b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def test_words():\n",
    "    if not isinstance(loaded_words, list):\n",
    "        print(f\"Expected words to be a list\")\n",
    "        return\n",
    "    if (len_words := len(loaded_words)) != (expected_words := 32033):\n",
    "        print(f\"Expected {expected_words} elements in words, found {len_words} elements\")\n",
    "        return\n",
    "    sorted_words = sorted(loaded_words)\n",
    "    if (zeroth_word := sorted_words[0]) != (expected_zeroth := \"aaban\"):\n",
    "        print(f\"Expected zeroth word in words to be '{expected_zeroth}', was '{zeroth_word}'\")\n",
    "        return\n",
    "    if (final_word := sorted_words[-1]) != (expected_final := \"zzyzx\"):\n",
    "        print(f\"Expected final word in words to be '{expected_final}', was '{final_word}'\")\n",
    "        return\n",
    "    print(\"load_words looks good. Onwards!\")\n",
    "loaded_words = load_words()\n",
    "test_words()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ed4466",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Step 1: Map characters to indices\n",
    "\n",
    "Write a function that takes the following arguments:\n",
    "* ```words``` (list of strings)\n",
    "\n",
    "And returns:\n",
    "* a dict (```stoi```) where\n",
    "  * the key is a character from ```words``` (including '.' for start/end),\n",
    "  * the value is a unique integer, and\n",
    "  * all the values are in the range from 0 to ```len(stoi) - 1``` (no gaps)\n",
    "\n",
    "We'll use these unique integers as an index to represent the characters in a Tensor in later steps\n",
    "\n",
    "Note that for this list of words, the same value of ```stoi``` could be generated without looking at the words at all,\n",
    "but simply by using all the lowercase letters and a period. This approach would be more efficient for this exercise,\n",
    "but will not generalize well conceptually to more complex models in future exercises.\n",
    "\n",
    "Video: [0:09:22](https://youtu.be/TCH_1BHY58I?t=562)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ef782d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_stoi(words):\n",
    "# TODO: Implement solution here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e24291",
   "metadata": {
    "deletable": false,
    "editable": false,
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def test_get_stoi():\n",
    "    bigrams = [\n",
    "        ('.', 'h'),\n",
    "        ('h', 'i'),\n",
    "        ('i', '.'),\n",
    "        ('.', 'b'),\n",
    "        ('b', 'y'),\n",
    "        ('y', 'e'),\n",
    "        ('e', '.'),\n",
    "    ]\n",
    "    expected_s = sorted(['.', 'h', 'i', 'b', 'y', 'e'])\n",
    "    stoi = get_stoi(bigrams)\n",
    "    if not isinstance(stoi, dict):\n",
    "        print(f\"Expected stoi to be a dict\")\n",
    "        return\n",
    "    s = sorted(stoi.keys())\n",
    "    if s != expected_s:\n",
    "        print(f\"Expected stoi keys to be {expected_s} when sorted, were {s}\")\n",
    "        return\n",
    "    expected_i = list(range(len(s)))\n",
    "    i = sorted(stoi.values())\n",
    "    if i != expected_i:\n",
    "        print(f\"Expected stoi values to be {expected_i} when sorted, were {i}\")\n",
    "        return\n",
    "    print(\"get_stoi looks good. Onwards!\")\n",
    "test_get_stoi()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6603e1b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Step 2: Map indices to characters\n",
    "\n",
    "Objective: Write a function that takes the following arguments:\n",
    "* a dict (```stoi```) as defined in step 2\n",
    "\n",
    "And returns:\n",
    "* a dict (```itos```) where ```itos``` contains the same key-value pairs as ```stoi``` but with keys and values swapped.\n",
    "\n",
    "E.g. if ```stoi == {'.' : 0, 'b' : 1, 'z', 2}```, then ```itos == {0 : '.', 1 : 'b', 2 : 'z'}```\n",
    "\n",
    "Video: [0:09:22](https://youtu.be/TCH_1BHY58I?t=562)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f179c5e6",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_itos(stoi):\n",
    "# TODO: Implement solution here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c0410c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def test_get_itos():\n",
    "    stoi = {elem:idx for idx, elem in enumerate(string.ascii_lowercase + \".\")}\n",
    "    itos = get_itos(stoi)\n",
    "    if not isinstance(itos, dict):\n",
    "        print(f\"Expected stoi to be a dict\")\n",
    "        return\n",
    "    for c in string.ascii_lowercase + \".\":\n",
    "        c_i = stoi[c]\n",
    "        if (expected_c := itos[c_i]) != c:\n",
    "            print(f\"Expected itos[{c_i}] to be {expected_c}, was {c}\")\n",
    "    print(\"get_itos looks good. Onwards!\")\n",
    "test_get_itos()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c984609",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Step 3: Generate inputs ```X``` and outputs ```Y```\n",
    "\n",
    "Write a function that takes the following arguments:\n",
    "* a list of strings (```words``` from the preamble)\n",
    "* a dict of characters to integers (```stoi``` from step 2)\n",
    "* an integer (```block_size```) that specifies how many characters to take into account when predicting the next one\n",
    "\n",
    "And returns:\n",
    "* a two-dimensional torch.Tensor ```X``` with each sequence of characters of length block_size from the words in ```words```\n",
    "* a one-dimensional torch.Tensor ```Y``` with the character that follows each sequence in ```x```\n",
    "\n",
    "Video: [0:09:35](https://youtu.be/TCH_1BHY58I?t=575)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdda3a69",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def get_X_and_Y(words, stoi, block_size):\n",
    "    X = []\n",
    "    Y = []\n",
    "# TODO: Implement solution here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91f3ba1",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "def test_get_X_and_Y():\n",
    "    words = [\n",
    "        \"hi\",\n",
    "        \"bye\",\n",
    "    ]\n",
    "    stoi = {\n",
    "        '.': 0,\n",
    "        'h': 1,\n",
    "        'i': 2,\n",
    "        'b': 3,\n",
    "        'y': 4,\n",
    "        'e': 5,\n",
    "    }\n",
    "    block_size = 3\n",
    "\n",
    "    (X, Y) = get_X_and_Y(words, stoi, block_size)\n",
    "\n",
    "    if not torch.is_tensor(X):\n",
    "        print(f\"Expected X to be a tensor, was {type(X)}\")\n",
    "        return\n",
    "    if not torch.is_tensor(Y):\n",
    "        print(f\"Expected Y to be a tensor, was {type(Y)}\")\n",
    "        return\n",
    "    expected_X = torch.tensor([\n",
    "        [0, 0, 0],\n",
    "        [0, 0, 1],\n",
    "        [0, 1, 2],\n",
    "        [1, 2, 0],\n",
    "        [2, 0, 0],\n",
    "        [0, 0, 0],\n",
    "        [0, 0, 3],\n",
    "        [0, 3, 4],\n",
    "        [3, 4, 5],\n",
    "        [4, 5, 0],\n",
    "        [5, 0, 0],\n",
    "    ])\n",
    "    expected_Y = torch.tensor([\n",
    "        1,\n",
    "        2,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        3,\n",
    "        4,\n",
    "        5,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "    ])\n",
    "    if (shape_X := X.shape) != (expected_shape_X := expected_X.shape):\n",
    "        print(f\"Expected shape of X for test case to be {expected_shape_X}, was {shape_X}\")\n",
    "        return\n",
    "    if not X.equal(expected_X):\n",
    "        print(f\"Expected X for test case to be {expected_X}, was {X}\")\n",
    "        return\n",
    "    if not Y.equal(expected_Y):\n",
    "        print(f\"Expected Y for test case to be {expected_Y}, was {Y}\")\n",
    "        return\n",
    "    print(\"get_x_and_y looks good. Onwards!\")\n",
    "test_get_X_and_Y()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05b0c03",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Step 4: Initialize vector embedding lookup table ```C```\n",
    "\n",
    "Write a function that takes the following arguments:\n",
    "* An integer (```indices```) representing the number of indices in ```stoi``` to embed\n",
    "* An integer (```embed_dimensions```) representing the number of dimensions the embedded vectors will have\n",
    "* A ```torch.Generator``` (```gen```) to provide (pseudo)random initial values for the parameters\n",
    "\n",
    "And returns:\n",
    "* a ```torch.Tensor``` of ```float64``` (```C```) representing the random initial vector for each index.\n",
    "\n",
    "Video: [0:12:19](https://youtu.be/TCH_1BHY58I?t=739)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89239d3f",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def get_C(indices, embed_dimensions, gen):\n",
    "# TODO: Implement solution here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46893743",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "def test_get_C():\n",
    "    indices = 7\n",
    "    embed_dimensions = 4\n",
    "    gen = torch.Generator()\n",
    "    gen.manual_seed(12345)\n",
    "    C = get_C(indices, embed_dimensions, gen)\n",
    "    if not torch.is_tensor(C):\n",
    "        print(f\"Expected C to be a tensor, was {type(C)}\")\n",
    "        return\n",
    "    if not torch.is_floating_point(C):\n",
    "        print(f\"Expected C to be a tensor of floating point.\")\n",
    "        return\n",
    "    if (shape_C := C.shape) != (expected_shape_C := (indices, embed_dimensions)):\n",
    "        print(f\"Expected shape of X for test case to be {expected_shape_C}, was {shape_C}\")\n",
    "        return\n",
    "    for i in range(len(C)):\n",
    "        for j in range(len(C)):\n",
    "            if i == j:\n",
    "                continue\n",
    "            if C[i].equal(C[j]):\n",
    "                print(f\"Rows {i} and {j} of C are too similar.\")\n",
    "                print(f\"{C[i]=}\")\n",
    "                print(f\"{C[j]=}\")\n",
    "                return\n",
    "    print(\"get_C looks good. Onwards!\")\n",
    "test_get_C()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d90e4c9",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Step : Convert X to tensor vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d6ba11",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Step : Initialize hidden layer coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051842fc",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Step : Forward propagate through hidden layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2b5db0",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Step : Initialize output layer coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9c686f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Step : Forward propagate through output layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a7b566",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Step : Calculate loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4bd3b0",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Step : Gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf605b7",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Step : Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1589a2",
   "metadata": {
    "deletable": false,
    "editable": false,
    "lines_to_next_cell": 3
   },
   "source": [
    "### Step : Generate words"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
