{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45db16ed",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "\n",
    "def load_words():\n",
    "    words = open(\"../names.txt\").read().splitlines()\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723987a4",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "\n",
    "def generate_bigrams(words):\n",
    "    bigrams = []\n",
    "    for word in words:\n",
    "        bigrams.append(('.', word[0]))\n",
    "        for pos in range(len(word) - 1):\n",
    "            bigrams.append((word[pos], word[pos + 1]))\n",
    "        bigrams.append((word[-1], '.'))\n",
    "    return bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff8fc52",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_stoi(bigrams):\n",
    "    chars = set()\n",
    "    for bigram in bigrams:\n",
    "        chars.add(bigram[0])\n",
    "        chars.add(bigram[1])\n",
    "    stoi = { v:k for (k, v) in enumerate(sorted(chars))}\n",
    "    return stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c038c6cd",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_itos(stoi):\n",
    "    itos = {stoi[c]:c for c in stoi}\n",
    "    return itos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9453e0",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_x_and_y(bigrams, stoi):\n",
    "    x = torch.tensor(list(map(lambda bigram : stoi[bigram[0]], bigrams)))\n",
    "    y = torch.tensor(list(map(lambda bigram : stoi[bigram[-1]], bigrams)))\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5789e69",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "def initialize_w_b(stoi):\n",
    "    stoi_n = len(stoi)\n",
    "    W = torch.rand((stoi_n,stoi_n), dtype=torch.float64, requires_grad=True)\n",
    "    b = torch.zeros((1,stoi_n),dtype=torch.float64, requires_grad=True)\n",
    "\n",
    "    return W, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea69c5f6",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "\n",
    "def forward_prop(x, W, b):\n",
    "    one_hot = torch.nn.functional.one_hot(x).double()\n",
    "    output = torch.matmul(one_hot, W) + b\n",
    "\n",
    "    softmax = output.exp()\n",
    "    softmax = softmax / softmax.sum(1, keepdim=True)\n",
    "\n",
    "    return softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d364aa60",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "\n",
    "def calculate_loss(y_hat, y):\n",
    "    match_probabilities = y_hat[torch.arange(len(y)), y]\n",
    "    neg_log_likelihood = -match_probabilities.log().mean()\n",
    "    return neg_log_likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07b43c1",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "\n",
    "def descend_gradient(W, b, learning_rate):\n",
    "    W.data -= learning_rate * W.grad\n",
    "    b.data -= learning_rate * b.grad\n",
    "    return W, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca9a159",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main():\n",
    "    words = load_words()\n",
    "    bigrams = generate_bigrams(words)\n",
    "    stoi = get_stoi(bigrams)\n",
    "    itos = get_itos(stoi)\n",
    "    x, y = get_x_and_y(bigrams, stoi)\n",
    "    W, b = initialize_w_b(stoi)\n",
    "    for i in range(1, 1001, 1):\n",
    "        y_hat = forward_prop(x,W,b)\n",
    "        loss = calculate_loss(y_hat, y)\n",
    "        if i % 10 == 0:\n",
    "            print(f\"Round {i} loss: {loss.item()}\")\n",
    "        W.grad = None\n",
    "        b.grad = None\n",
    "        loss.backward()\n",
    "        W, b = descend_gradient(W, b, 10.0)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
