{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7113d197",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Preamble: Load data\n",
    "\n",
    "Objective: Load a list of words from the [names.txt](https://github.com/karpathy/makemore/blob/master/names.txt) file into a list variable named ```words```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45db16ed",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def load_words():\n",
    "    words_url = 'https://raw.githubusercontent.com/karpathy/makemore/master/names.txt'\n",
    "    words = requests.get(words_url).text.splitlines()\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efa3cb5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def test_words():\n",
    "    words = load_words()\n",
    "    if not isinstance(words, list):\n",
    "        print(f\"Expected words to be a list\")\n",
    "        return\n",
    "    if (len_words := len(words)) != (expected_words := 32033):\n",
    "        print(f\"Expected {expected_words} elements in words, found {len_words} elements\")\n",
    "        return\n",
    "    if (zeroth_word := words[0]) != (expected_zeroth := \"emma\"):\n",
    "        print(f\"Expected zeroth word in words to be '{expected_zeroth}', was '{zeroth_word}'\")\n",
    "        return\n",
    "    if (final_word := words[-1]) != (expected_final := \"zzyzx\"):\n",
    "        print(f\"Expected final word in words to be '{expected_final}', was '{final_word}'\")\n",
    "        return\n",
    "    print(\"words looks good. Onwards!\")\n",
    "test_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723987a4",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "\n",
    "def generate_bigrams(words):\n",
    "    bigrams = []\n",
    "    for word in words:\n",
    "        bigrams.append(('.', word[0]))\n",
    "        for pos in range(len(word) - 1):\n",
    "            bigrams.append((word[pos], word[pos + 1]))\n",
    "        bigrams.append((word[-1], '.'))\n",
    "    return bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff8fc52",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_stoi(bigrams):\n",
    "    chars = set()\n",
    "    for bigram in bigrams:\n",
    "        chars.add(bigram[0])\n",
    "        chars.add(bigram[1])\n",
    "    stoi = { v:k for (k, v) in enumerate(sorted(chars))}\n",
    "    return stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c038c6cd",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_itos(stoi):\n",
    "    itos = {stoi[c]:c for c in stoi}\n",
    "    return itos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9453e0",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_x_and_y(bigrams, stoi):\n",
    "    x = torch.tensor(list(map(lambda bigram : stoi[bigram[0]], bigrams)))\n",
    "    y = torch.tensor(list(map(lambda bigram : stoi[bigram[-1]], bigrams)))\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5789e69",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "def initialize_w_b(stoi):\n",
    "    stoi_n = len(stoi)\n",
    "    W = torch.rand((stoi_n,stoi_n), dtype=torch.float64, requires_grad=True)\n",
    "    b = torch.zeros((1,stoi_n),dtype=torch.float64, requires_grad=True)\n",
    "\n",
    "    return W, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea69c5f6",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "\n",
    "def forward_prop(x, W, b):\n",
    "    one_hot = torch.nn.functional.one_hot(x).double()\n",
    "    output = torch.matmul(one_hot, W) + b\n",
    "\n",
    "    softmax = output.exp()\n",
    "    softmax = softmax / softmax.sum(1, keepdim=True)\n",
    "\n",
    "    return softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d364aa60",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "\n",
    "def calculate_loss(y_hat, y):\n",
    "    match_probabilities = y_hat[torch.arange(len(y)), y]\n",
    "    neg_log_likelihood = -match_probabilities.log().mean()\n",
    "    return neg_log_likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07b43c1",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "\n",
    "def descend_gradient(W, b, learning_rate):\n",
    "    W.data -= learning_rate * W.grad\n",
    "    b.data -= learning_rate * b.grad\n",
    "    return W, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca9a159",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main():\n",
    "    words = load_words()\n",
    "    bigrams = generate_bigrams(words)\n",
    "    stoi = get_stoi(bigrams)\n",
    "    itos = get_itos(stoi)\n",
    "    x, y = get_x_and_y(bigrams, stoi)\n",
    "    W, b = initialize_w_b(stoi)\n",
    "    for i in range(1, 1001, 1):\n",
    "        y_hat = forward_prop(x,W,b)\n",
    "        loss = calculate_loss(y_hat, y)\n",
    "        if i % 10 == 0:\n",
    "            print(f\"Round {i} loss: {loss.item()}\")\n",
    "        W.grad = None\n",
    "        b.grad = None\n",
    "        loss.backward()\n",
    "        W, b = descend_gradient(W, b, 10.0)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
